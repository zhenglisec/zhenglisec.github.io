---
title:          "Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis"
date:           2023-01-01
selected:       false
#type:           publication
#tags:           ["# continual learning", "# few-shot learning"]
pub:            "arxiv 2023"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
# pub_date:       "2025"
semantic_scholar_id: c108f86e614082c6d58245c86b3410e4680c0689  # use this to retrieve citation count
abstract: >-
  Large text-to-image models have shown remarkable performance in synthesizing high-quality images. In particular, the subject-driven model makes it possible to personalize the image synthesis for a specific subject, e.g., a human face or an artistic style, by fine-tuning the generic text-to-image model with a few images from that subject. Nevertheless, misuse of subject-driven image synthesis may violate the authority of subject owners. For example, malicious users may use subject-driven synthesis to mimic specific artistic styles or to create fake facial images without authorization. To protect subject owners against such misuse, recent attempts have commonly relied on adversarial examples to indiscriminately disrupt subject-driven image synthesis. However, this essentially prevents any benign use of subject-driven synthesis based on protected images. ...
cover:          /assets/images/covers/2023-1arxiv.png
authors:
  - Yihan Ma
  - Zhengyu Zhao
  - Xinlei He
  - Zheng Li
  - Michael Backes
  - Yang Zhang
links:
  Paper: https://arxiv.org/pdf/2306.07754
---
